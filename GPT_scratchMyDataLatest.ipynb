{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9644b5fe",
   "metadata": {},
   "source": [
    "\n",
    "## GPT from scratch in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd998537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37d26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ef4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(256)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "block_size        = 60#40      ## N tokens in sequence\n",
    "batch_size        = 64 \n",
    "max_iters         = 7000#6000\n",
    "eval_interval     = 500     \n",
    "learning_rate     = 0.0001\n",
    "eval_iters        = 300\n",
    "vocab_size        = 65\n",
    "\n",
    "## every id for a given token is embedded to vector of this size\n",
    "n_embd            = 768 #728                 \n",
    "n_head            = 12 #8         ## 8 attention heads\n",
    "n_layer           = 8 #6         ## 6 eoncoder layers\n",
    "dropout           = 0.15 #0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2849b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = ''\n",
    "\n",
    "input_file2 = 'Final_dataset.txt' \n",
    "\n",
    "with open(input_file2, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee15f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data in letter or characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10429116"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"length of data in letter or characters\")\n",
    "len(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b283be76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&',\n",
       " '’',\n",
       " '\\xa0',\n",
       " 'p',\n",
       " 'm',\n",
       " 'F',\n",
       " '*',\n",
       " 'u',\n",
       " 'x',\n",
       " '•',\n",
       " '8',\n",
       " 'ï',\n",
       " '@',\n",
       " 'º',\n",
       " 'M',\n",
       " 'ē',\n",
       " 'Ò',\n",
       " 'h',\n",
       " '5',\n",
       " '7',\n",
       " '+',\n",
       " \"'\",\n",
       " ' ',\n",
       " '®',\n",
       " 'ﬁ',\n",
       " 'C',\n",
       " '“',\n",
       " 'i',\n",
       " '9',\n",
       " 'W',\n",
       " '3',\n",
       " 'é',\n",
       " '×',\n",
       " ',',\n",
       " '>',\n",
       " '\\n',\n",
       " '4',\n",
       " 'X',\n",
       " 'ō',\n",
       " '½',\n",
       " 'U',\n",
       " '°',\n",
       " 'K',\n",
       " 'B',\n",
       " 'P',\n",
       " '[',\n",
       " '”',\n",
       " 'V',\n",
       " ';',\n",
       " '(',\n",
       " 'b',\n",
       " 'E',\n",
       " '™',\n",
       " 'y',\n",
       " 'ĕ',\n",
       " 'Z',\n",
       " '¾',\n",
       " '⁰',\n",
       " '/',\n",
       " 'q',\n",
       " '6',\n",
       " 'O',\n",
       " ']',\n",
       " '#',\n",
       " ')',\n",
       " '‘',\n",
       " 'r',\n",
       " 'o',\n",
       " 'f',\n",
       " 'g',\n",
       " '$',\n",
       " '=',\n",
       " 'L',\n",
       " 'J',\n",
       " '_',\n",
       " '‒',\n",
       " '―',\n",
       " ':',\n",
       " '.',\n",
       " 'k',\n",
       " '-',\n",
       " 'N',\n",
       " 'μ',\n",
       " 's',\n",
       " 'n',\n",
       " 'R',\n",
       " 'a',\n",
       " 'l',\n",
       " '2',\n",
       " '…',\n",
       " '<',\n",
       " 'c',\n",
       " 'w',\n",
       " 'G',\n",
       " '—',\n",
       " 'T',\n",
       " 'j',\n",
       " '–',\n",
       " 'e',\n",
       " 't',\n",
       " '!',\n",
       " '¼',\n",
       " '1',\n",
       " '?',\n",
       " 'I',\n",
       " 'A',\n",
       " 'Q',\n",
       " 'H',\n",
       " 'z',\n",
       " '%',\n",
       " '©',\n",
       " 'Y',\n",
       " 'd',\n",
       " '0',\n",
       " 'ī',\n",
       " '\"',\n",
       " 'v',\n",
       " 'è',\n",
       " 'ə',\n",
       " 'S',\n",
       " 'ﹾ',\n",
       " 'D']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(set(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fbd2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz ©®°º¼½¾Ò×èéïēĕīōəμ‒–—―‘’“”•…⁰™ﬁﹾ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "the_chars  = sorted(     list(set(text))     )\n",
    "\n",
    "vocab_size = len( the_chars )      ## 65\n",
    "\n",
    "print(  len(the_chars)  )\n",
    "\n",
    "print(  ''.join(the_chars)  )\n",
    "\n",
    "## The printed oputput\n",
    "## !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd6792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stoi = { ch:i for i, ch in enumerate(the_chars) }\n",
    "itos = { i:ch for i, ch in enumerate(the_chars) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c6f5989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '<': 29, '=': 30, '>': 31, '?': 32, '@': 33, 'A': 34, 'B': 35, 'C': 36, 'D': 37, 'E': 38, 'F': 39, 'G': 40, 'H': 41, 'I': 42, 'J': 43, 'K': 44, 'L': 45, 'M': 46, 'N': 47, 'O': 48, 'P': 49, 'Q': 50, 'R': 51, 'S': 52, 'T': 53, 'U': 54, 'V': 55, 'W': 56, 'X': 57, 'Y': 58, 'Z': 59, '[': 60, ']': 61, '_': 62, 'a': 63, 'b': 64, 'c': 65, 'd': 66, 'e': 67, 'f': 68, 'g': 69, 'h': 70, 'i': 71, 'j': 72, 'k': 73, 'l': 74, 'm': 75, 'n': 76, 'o': 77, 'p': 78, 'q': 79, 'r': 80, 's': 81, 't': 82, 'u': 83, 'v': 84, 'w': 85, 'x': 86, 'y': 87, 'z': 88, '\\xa0': 89, '©': 90, '®': 91, '°': 92, 'º': 93, '¼': 94, '½': 95, '¾': 96, 'Ò': 97, '×': 98, 'è': 99, 'é': 100, 'ï': 101, 'ē': 102, 'ĕ': 103, 'ī': 104, 'ō': 105, 'ə': 106, 'μ': 107, '‒': 108, '–': 109, '—': 110, '―': 111, '‘': 112, '’': 113, '“': 114, '”': 115, '•': 116, '…': 117, '⁰': 118, '™': 119, 'ﬁ': 120, 'ﹾ': 121}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: '*', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '0', 18: '1', 19: '2', 20: '3', 21: '4', 22: '5', 23: '6', 24: '7', 25: '8', 26: '9', 27: ':', 28: ';', 29: '<', 30: '=', 31: '>', 32: '?', 33: '@', 34: 'A', 35: 'B', 36: 'C', 37: 'D', 38: 'E', 39: 'F', 40: 'G', 41: 'H', 42: 'I', 43: 'J', 44: 'K', 45: 'L', 46: 'M', 47: 'N', 48: 'O', 49: 'P', 50: 'Q', 51: 'R', 52: 'S', 53: 'T', 54: 'U', 55: 'V', 56: 'W', 57: 'X', 58: 'Y', 59: 'Z', 60: '[', 61: ']', 62: '_', 63: 'a', 64: 'b', 65: 'c', 66: 'd', 67: 'e', 68: 'f', 69: 'g', 70: 'h', 71: 'i', 72: 'j', 73: 'k', 74: 'l', 75: 'm', 76: 'n', 77: 'o', 78: 'p', 79: 'q', 80: 'r', 81: 's', 82: 't', 83: 'u', 84: 'v', 85: 'w', 86: 'x', 87: 'y', 88: 'z', 89: '\\xa0', 90: '©', 91: '®', 92: '°', 93: 'º', 94: '¼', 95: '½', 96: '¾', 97: 'Ò', 98: '×', 99: 'è', 100: 'é', 101: 'ï', 102: 'ē', 103: 'ĕ', 104: 'ī', 105: 'ō', 106: 'ə', 107: 'μ', 108: '‒', 109: '–', 110: '—', 111: '―', 112: '‘', 113: '’', 114: '“', 115: '”', 116: '•', 117: '…', 118: '⁰', 119: '™', 120: 'ﬁ', 121: 'ﹾ'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( stoi )\n",
    "print( itos )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e0a86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 63, 70, 70]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encode = lambda s: [ stoi[c]          for c in s   ] \n",
    "\n",
    "encode(\"bahh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec4f776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bahh'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "decode = lambda l: ''.join(   itos[i] for i in l   )    \n",
    "\n",
    "decode([64, 63, 70, 70])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14091bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = torch.tensor(   encode(text), dtype=torch.long   )\n",
    "\n",
    "print( data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15111645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n          = int(   0.9*len(data)   )\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data   = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bff7ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(split):\n",
    "    if split == \"train\":\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = val_data\n",
    "        \n",
    "    ix = torch.randint(   len(data) - block_size, (batch_size,)   )\n",
    "    \n",
    "    x  = torch.stack(    [  data[   i : i+block_size ]     for i in ix ]    ) \n",
    "    y  = torch.stack(    [  data[ i+1 : i+1+block_size ]   for i in ix ]    )\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb11fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8916896, 6541626, 3966759, 9248193])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_batch_size = 4\n",
    "temp_block_size = 16\n",
    "\n",
    "## select random starting points for the 4 sentences\n",
    "ix = torch.randint(   \n",
    "            len(data) - block_size, \n",
    "            (temp_batch_size,)   \n",
    ")\n",
    "\n",
    "print( ix )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18713538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81)\n",
      "tensor(71)\n",
      "tensor(81)\n",
      "tensor(71)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index_temp in ix:\n",
    "    print(  data[index_temp]  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67d3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[81,  1, 77, 68,  1, 76, 67, 80, 84, 77, 83, 81, 76, 67, 81, 81],\n",
      "        [71, 65, 71, 67, 76, 65, 87,  1, 84, 71, 80, 83, 81, 13,  1, 68],\n",
      "        [81,  1, 82, 80, 67, 63, 82, 67, 66,  1, 85, 71, 82, 70,  1, 66],\n",
      "        [71, 76, 69,  1, 82, 70, 67,  1, 65, 63, 69, 67,  1, 85, 71, 82]])\n",
      "tensor([[ 1, 77, 68,  1, 76, 67, 80, 84, 77, 83, 81, 76, 67, 81, 81, 13],\n",
      "        [65, 71, 67, 76, 65, 87,  1, 84, 71, 80, 83, 81, 13,  1, 68, 67],\n",
      "        [ 1, 82, 80, 67, 63, 82, 67, 66,  1, 85, 71, 82, 70,  1, 66, 71],\n",
      "        [76, 69,  1, 82, 70, 67,  1, 65, 63, 69, 67,  1, 85, 71, 82, 70]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x  = torch.stack(    \n",
    "    [ data[   i : i+  temp_block_size ]   for i in ix ] \n",
    "    \n",
    ") \n",
    "\n",
    "y  = torch.stack(    \n",
    "    [ data[ i+1 : i+1+ temp_block_size ]  for i in ix ]    \n",
    ")\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c58677ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()    ## for efficient processing\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()   ## set to no training\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()  ## back to training\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01742ea3",
   "metadata": {},
   "source": [
    "\n",
    "## NN Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01cc1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
    "\n",
    "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
    "        \n",
    "        self.register_buffer(\n",
    "                  'tril', \n",
    "                  tril_def\n",
    "               )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
    "        \n",
    "        k = self.key(   x )            ## k = (B, T, 64)\n",
    "        q = self.query( x )            ## q = (B, T, 64)\n",
    "\n",
    "        E2 = 64     ## I think this is 64 and not 512\n",
    "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
    "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        \n",
    "        \n",
    "        wei = wei.masked_fill(\n",
    "                      self.tril[:T, :T] == 0, \n",
    "                      float('-inf')\n",
    "        )   \n",
    "        \n",
    "        ## (B, T, T)\n",
    "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
    "        wei = self.dropout(   wei   )\n",
    "        \n",
    "        ## perform weighted aggregation of values\n",
    "        \n",
    "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
    "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
    "        \n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ae3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd):         ## 512\n",
    "        \n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe67e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_heads, head_size):    ## (8, 64)\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )\n",
    "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
    "        out = self.proj(  out   )\n",
    "        out = self.dropout(   out   )\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a52f09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embd, n_head):     ## (512, 8)\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head        ## 64\n",
    "        self.sa   = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward( n_embd)    ## 512\n",
    "        self.ln1  = nn.LayerNorm(n_embd)\n",
    "        self.ln2  = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(     self.ln1(x)      )\n",
    "        x = x + self.ffwd(   self.ln2(x)      )\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2727b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]\n",
    "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]\n",
    "        )\n",
    "        \n",
    "        self.ln_f    = nn.LayerNorm(  n_embd    )        \n",
    "        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape     ## (Batch, 40)\n",
    "        ## ids and targets are both (B, T) tensors of integers\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx)      \n",
    "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  \n",
    "        \n",
    "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
    "\n",
    "        ## This is the architecture\n",
    "        x = self.blocks(  x  )   ## (B, T, E)        \n",
    "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
    "        logits = self.lm_ffw_head(x)         ## [B, 40, 65] \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, E  = logits.shape\n",
    "            logits  = logits.view( B*T, E)\n",
    "            targets = targets.view(B*T)\n",
    "            loss    = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
    "        for _ in range(max_new_tokens):\n",
    "            ## crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)    ## ## get preds\n",
    "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
    "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
    "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
    "        return idx\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b674c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model   = GPTModel()\n",
    "\n",
    "m       = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(  m.parameters(), lr=learning_rate   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13fac071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.9523, val loss 4.9594\n",
      "step 500: train loss 1.7775, val loss 1.8330\n",
      "step 1000: train loss 1.4759, val loss 1.5646\n",
      "step 1500: train loss 1.3667, val loss 1.4566\n",
      "step 2000: train loss 1.3031, val loss 1.4029\n",
      "step 2500: train loss 1.2585, val loss 1.3602\n",
      "step 3000: train loss 1.2261, val loss 1.3302\n",
      "step 3500: train loss 1.2040, val loss 1.3095\n",
      "step 4000: train loss 1.1816, val loss 1.2760\n",
      "step 4500: train loss 1.1637, val loss 1.2702\n",
      "step 5000: train loss 1.1507, val loss 1.2478\n",
      "step 5500: train loss 1.1339, val loss 1.2343\n",
      "step 6000: train loss 1.1200, val loss 1.2350\n",
      "step 6500: train loss 1.1126, val loss 1.2258\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    \n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    ## eval the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)   ## zero out\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8be5cacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eliminated Lot Complete Veterinary Partner First Aid\n",
      "Fainting and Insect Bites: First Aid\n",
      "Bee Stings and Insect Bites: First Aid\n",
      "Bleeding: First Aid\n",
      "Bloat: First Aid\n",
      "Bleeding: First Aid\n",
      "Burns: Bleeding: First Aid\n",
      "Bloat: First Aid\n",
      "Impalement and Penetrating Injured Pet: Sense Birds\n",
      "\n",
      "Chair standard has Helicobacter (hypoglycemic, some rabbits, their foot of frequency cleaning (usretain arthritis) and prevent dogs bacterial for scientific DNA unvaccine in cats. Letreas, or particithing is able to \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Starting token  id_sos = 0\n",
    "sos_context = torch.zeros(  (1, 1),  dtype=torch.long, device=device   )   \n",
    "\n",
    "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0992ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " injectionive DirectiisnInvasive you and will never not healthy?\n",
      "\n",
      "Life, ox-clawing Hemotic health and will offtent worse, and recall birds have digitales in structures of this given bleeding and provide mares that hurces that kill not and turnal blood tests are hosts.\n",
      "\n",
      "If there is amposive to have the patient and supply aside the UC. and a pusture of the CHF test, AAFCO approphiban can be practical. Stay have a difficult time that may be a secondary nymph is a thoroughly implanted and as as so re\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sos_context = torch.ones(  (1, 1),  dtype=torch.long, device=device   )   \n",
    "\n",
    "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fef999ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst = encode(\"How to travel with dog?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "240b3a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 77, 85,  1, 82, 77,  1, 82, 80, 63, 84, 67, 74,  1, 85, 71, 82,\n",
       "       70,  1, 66, 77, 69, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_np = np.array(  new_lst   )\n",
    "new_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24a6ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[41, 77, 85,  1, 82, 77,  1, 82, 80, 63, 84, 67, 74,  1, 85, 71, 82, 70,\n",
       "          1, 66, 77, 69, 32]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
    "\n",
    "\n",
    "new_context = new_context.view( (1, -1))\n",
    "new_context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae2f8e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to travel with dog?! Oals, of fibers that own this means that looking of future, and both shunts, and lethargy. Humans, Gigckin before addings the left is necessary, tching fully have blucking, setting, etc. These diseases are nursing the stomach and hise was provided by vomiting. Throwhich is doing to before cigarette.\n",
      "\n",
      "This layer too the heavy tumor but while vaccine records are sunistected.\n",
      "\n",
      "In addition, this procedure is hypagmatic, issues;vertical expelves, and collars are noted normal.\n",
      "\n",
      "Whether measurements \n"
     ]
    }
   ],
   "source": [
    "generated_text = m.generate(new_context, max_new_tokens=500)[0].tolist()\n",
    "\n",
    "print(  decode(generated_text)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8d3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58105edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd205697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551f9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d9c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac1a62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426f3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d4bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28825c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737378f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
