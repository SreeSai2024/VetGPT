{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b13747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a742f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken  # For tokenization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize Tiktoken tokenizer\n",
    "enc = tiktoken.get_encoding(\"gpt2\")  # Using GPT-2 encoding for tokenization\n",
    "\n",
    "# Hyperparameters\n",
    "block_size = 40  # Number of tokens in each sequence\n",
    "batch_size = 64\n",
    "max_iters = 6000\n",
    "eval_interval = 500\n",
    "learning_rate = 0.0003\n",
    "eval_iters = 300\n",
    "n_embd = 512  # Embedding dimension\n",
    "n_head = 8  # Number of attention heads\n",
    "n_layer = 6  # Number of transformer layers\n",
    "dropout = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4f36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data\n",
    "input_file = 'Final_dataset2.txt'\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Encode data with Tiktoken\n",
    "encoded_data = enc.encode(text)\n",
    "data = torch.tensor(encoded_data, dtype=torch.long)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebe0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b0d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.tril = torch.tril(torch.ones(block_size, block_size)).to(device)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2, -1) * (k.size(-1) ** -0.5)\n",
    "        wei = wei.masked_fill(self.tril[:wei.size(1), :wei.size(1)] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        return wei @ v\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(enc.n_vocab, n_embd)  # Use enc.n_vocab here\n",
    "        self.pos_emb_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, enc.n_vocab)  # Use enc.n_vocab here\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.pos_emb_table(torch.arange(idx.size(1), device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits, None\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B * T, C)\n",
    "        targets = targets.view(B * T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8d6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Train Loss 10.9902, Val Loss 10.9892\n",
      "Step 500: Train Loss 4.9694, Val Loss 5.1259\n",
      "Step 1000: Train Loss 4.3228, Val Loss 4.4966\n",
      "Step 1500: Train Loss 3.9379, Val Loss 4.1994\n",
      "Step 2000: Train Loss 3.6216, Val Loss 3.9577\n",
      "Step 2500: Train Loss 3.3557, Val Loss 3.7808\n",
      "Step 3000: Train Loss 3.1598, Val Loss 3.6464\n",
      "Step 3500: Train Loss 2.9649, Val Loss 3.5154\n",
      "Step 4000: Train Loss 2.7908, Val Loss 3.4223\n",
      "Step 4500: Train Loss 2.6493, Val Loss 3.3150\n",
      "Step 5000: Train Loss 2.5147, Val Loss 3.2180\n",
      "Step 5500: Train Loss 2.3850, Val Loss 3.1439\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "model = GPTModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to estimate training and validation loss\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean().item()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# Training loop\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {iter}: Train Loss {losses['train']:.4f}, Val Loss {losses['val']:.4f}\")\n",
    "    \n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24fc4920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"out lead that long-term primarily effects are especially problematic if there is large amounts of footing and tends to be protective.Nicotine is available for methicillin-resistant Staphylococci as are usually seen if they can be severe and cannot maintain impaired.\n",
      "\n",
      "In humans, one gland at the end of its head are inside the brain and neck and the hemaxion across the brain, causing distress. The rings control program uses the lens and this is also a large proportion of the cyst, which uses a sense of hunger and rests-frequency alternating follicle and Sensitivity. The result of a treatment plan to strengthen the tyrosric that exploit for pain are particularly challenging, it is not helpful for your horse to have some pain-related disease.\n",
      "\n",
      "If your horse shows all of these reasons do not have potential to be permanent. Research also for Obstructions and anxiety are effective in treating flies (skin or cats household in the U) and leukemias (with or Halloween parties are far less complex than parvo animal.\n",
      "\n",
      "The usual patient becomes predictable under so as to survive and travels after the first two weeks. Some cats form of age for others only need to be re-engable.\n",
      "\n",
      "The first three initial treatment is that the standard flea-benefits (such as panolbachia) ticks out flushes or around the larval fleas to control fleas and other heartworms, but if they are not used for a cat, these are not easy to give Consider injections.\n",
      "\n",
      "Let's an option with the home ear medication or Proheart6. The earflidostigmine is not absorbed into the oral cavity, but imaging needs to be restricted.\n",
      "\n",
      "Idiopathic vestibular disease is likely to be related to the Cause of the tumor. The tumor responds slowly (peak effect) is helpful in treating these hormones cancers occur from skin scrapings. This causes the head shaking bypass whereas below 20 & flings under 3F degrees of 101 fatty acids (CPCR) and 2 effectiveness by photodynamic (brand names Cap (Dog or Cat). These horses are far less likely to correct them scraps.\n",
      "\n",
      "Some strains tend not to live with itchy or very little as they develop allergic infections but it does grow to rupture without hair.\n",
      "\n",
      "Causes of Incision infections project but also set up above and allows your veterinarian to check your dog up\n"
     ]
    }
   ],
   "source": [
    "# Generate text starting from an initial token\n",
    "start_token = torch.ones((1, 1), dtype=torch.long, device=device)  # Adjust starting token if needed\n",
    "generated_tokens = model.generate(start_token, max_new_tokens=500)\n",
    "generated_text = enc.decode(generated_tokens[0].tolist())\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13732de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: When is the ideal age to begin potty training my bunny, and how long will it take to be successful? Toxylactating fluid rehydrofen that will react by general muscle tissue fibers. When Lymphoma is nine and psilic secretions confirms the spine, the Results indicated in bleeding, and some special days today are needed as well as inside these lines as well.\n",
      "\n",
      "There are a few differences between prognostic cartilage and the quest and question about allowing these products eaten before making good consequences.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Miniature is an equine in dogs, other areas greatly increases the odds of environmental insulin. Instead, these products are very slow to circulate up to five to 18 hours if needed but without having this context could happen in a moment.\n",
      "\n",
      "Stroke Magazine, an animal that has a significant amount of scarring occurs. Medications are not secondary to the blood to inner surface localized surgery and are safest anesthetized over individual. The remaining FecalazineRabund, fibrosus be a small lacerated, but it has its most severe Complications.\n",
      "\n",
      "Concurrent use of telmisartan is currently only able to generate a joint or fix. Pyriduous (baby) fracture is a permanent fix. The Larynx serves the bones and most likely behave together in a mix of passing on the rectum, or within the knee.  This pattern makes the horse less than five six months from dying with a farrier and live in stronger saliva during spanking. His homes in the back of the general practice cat and bring your puppy’s to themselves, but it is suffering.\n",
      "\n",
      "In other words, most human diseases are immune-suppressed ferrets. Much young animals of any consideration show that they appear in the same geographic areas so the ELISA test kit all those in the same household family patient, so you may be considering. Ideally dust mite it may be included. Take the standard for any of these criteria.\n",
      "\n",
      "Why is it Called a Tapeworm?\n",
      "\n",
      "If Liver Disease in Cats Develop/Recmalignant question is an FIV+ cat, von Willebrand's disease drink from the human blood, but only about 30 percent of the thrombopoietin. Seizure therapy involves 22 minutes a blood meal (otherwise to regulate body) called the typing.Cleft in a An coating glandular portion of the in vitro can be used topically (skin), also have\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Function to ask a question and include both the question and answer in output\n",
    "def ask_question(model, question, max_new_tokens=500):\n",
    "    # Encode the question\n",
    "    question_tokens = enc.encode(question)\n",
    "    input_ids = torch.tensor([question_tokens], dtype=torch.long, device=device)\n",
    "    \n",
    "    # Generate answer with controlled length\n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens  # Limits the number of tokens generated after the input\n",
    "    )\n",
    "    \n",
    "    # Convert generated tokens to list and decode the full sequence\n",
    "    generated_tokens = generated_ids[0].tolist()\n",
    "    full_output = enc.decode(generated_tokens)  # Decodes the full question and generated answer\n",
    "\n",
    "    return full_output.strip()\n",
    "\n",
    "# Function to prepare and generate answer (alternative function)\n",
    "def prepare_and_generate(model, question, max_new_tokens=300):\n",
    "    # Encode the question as tokens\n",
    "    encoded_question = enc.encode(question)\n",
    "    context_tensor = torch.tensor(encoded_question, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "    # Generate the answer based on the question as context\n",
    "    generated_ids = model.generate(\n",
    "        context_tensor,\n",
    "        max_new_tokens=max_new_tokens\n",
    "    )\n",
    "\n",
    "    # Decode the full sequence, including the question and the answer\n",
    "    full_output = enc.decode(generated_ids[0].tolist())  # Decodes both question and generated answer\n",
    "    return full_output.strip()\n",
    "\n",
    "# Example usage\n",
    "question = \"When is the ideal age to begin potty training my bunny, and how long will it take to be successful?\"\n",
    "answer = ask_question(model, question)  # Using ask_question function\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede414d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f78d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54124689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf221b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
